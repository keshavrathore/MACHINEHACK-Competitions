{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073798,
     "end_time": "2020-09-28T06:46:43.203991",
     "exception": false,
     "start_time": "2020-09-28T06:46:43.130193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:02.542372Z",
     "iopub.status.busy": "2020-09-28T06:47:02.54139Z",
     "iopub.status.idle": "2020-09-28T06:47:14.668733Z",
     "shell.execute_reply": "2020-09-28T06:47:14.66799Z"
    },
    "papermill": {
     "duration": 12.235279,
     "end_time": "2020-09-28T06:47:14.668858",
     "exception": false,
     "start_time": "2020-09-28T06:47:02.433579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string as s\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "from sklearn.metrics  import f1_score, accuracy_score, multilabel_confusion_matrix, confusion_matrix, recall_score, precision_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from keras.utils import to_categorical\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.091591,
     "end_time": "2020-09-28T06:47:16.370421",
     "exception": false,
     "start_time": "2020-09-28T06:47:16.27883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \n",
       "0        a y-zoom on the piano roll would be useful.      1  \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0  \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1  \n",
       "3  i think we should stop logging requests to:\\r ...      1  \n",
       "4  expected behavior\\r alarm actions pid on and p...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(\"embold_train.json\").reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>config question  path-specific environment var...</td>\n",
       "      <td>issue description or question\\r \\r hey @artemg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crash indien vol</td>\n",
       "      <td>de simulator crasht als hij vol zit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unable to mine rocks</td>\n",
       "      <td>sarkasmo starting today, when i hit enter  act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not all whitelists are processed</td>\n",
       "      <td>create following rules... order of creation is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add ctx menu for idafree 70 and idafree 5</td>\n",
       "      <td>associated with .dll, .dll_, .exe, .exe_, .sc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  config question  path-specific environment var...   \n",
       "1                                   crash indien vol   \n",
       "2                               unable to mine rocks   \n",
       "3                   not all whitelists are processed   \n",
       "4          add ctx menu for idafree 70 and idafree 5   \n",
       "\n",
       "                                                body  \n",
       "0  issue description or question\\r \\r hey @artemg...  \n",
       "1                de simulator crasht als hij vol zit  \n",
       "2  sarkasmo starting today, when i hit enter  act...  \n",
       "3  create following rules... order of creation is...  \n",
       "4  associated with .dll, .dll_, .exe, .exe_, .sc,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(\"embold_test.json\").reset_index(drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use a 8bit typeface</td>\n",
       "      <td>since this is meant to emulate some old arcade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>implement wireless m-bus binding</td>\n",
       "      <td>_from  chris.pa...@googlemail.com  https://cod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add multilang support for timeago.js</td>\n",
       "      <td>currently it is only  en . \\r required to add ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scaleway - seg-fault on shutdown</td>\n",
       "      <td>tbr  irc  creates a new scaleway instance with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sistema de pintura: no se guardar los nuevos p...</td>\n",
       "      <td>este sp ya estaba asignado a un carro y se enc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                use a 8bit typeface   \n",
       "1                   implement wireless m-bus binding   \n",
       "2               add multilang support for timeago.js   \n",
       "3                   scaleway - seg-fault on shutdown   \n",
       "4  sistema de pintura: no se guardar los nuevos p...   \n",
       "\n",
       "                                                body  label  \n",
       "0  since this is meant to emulate some old arcade...      1  \n",
       "1  _from  chris.pa...@googlemail.com  https://cod...      1  \n",
       "2  currently it is only  en . \\r required to add ...      1  \n",
       "3  tbr  irc  creates a new scaleway instance with...      0  \n",
       "4  este sp ya estaba asignado a un carro y se enc...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ex_df = pd.read_json(\"embold_train_extra.json\")\n",
    "train_ex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:18.270567Z",
     "iopub.status.busy": "2020-09-28T06:47:18.269569Z",
     "iopub.status.idle": "2020-09-28T06:47:18.286091Z",
     "shell.execute_reply": "2020-09-28T06:47:18.28656Z"
    },
    "papermill": {
     "duration": 0.121779,
     "end_time": "2020-09-28T06:47:18.286728",
     "exception": false,
     "start_time": "2020-09-28T06:47:18.164949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  \n",
       "0        a y-zoom on the piano roll would be useful.      1  \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0  \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1  \n",
       "3  i think we should stop logging requests to:\\r ...      1  \n",
       "4  expected behavior\\r alarm actions pid on and p...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping news_id with category_id\n",
    "final_df = pd.concat([train_df, train_ex_df], ignore_index=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:18.702527Z",
     "iopub.status.busy": "2020-09-28T06:47:18.701685Z",
     "iopub.status.idle": "2020-09-28T06:47:18.705921Z",
     "shell.execute_reply": "2020-09-28T06:47:18.705259Z"
    },
    "papermill": {
     "duration": 0.107802,
     "end_time": "2020-09-28T06:47:18.706037",
     "exception": false,
     "start_time": "2020-09-28T06:47:18.598235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proposal  loadtranslation   to lazy load scopewithtranslation'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Sample Title\n",
    "final_df.iloc[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:18.906987Z",
     "iopub.status.busy": "2020-09-28T06:47:18.905819Z",
     "iopub.status.idle": "2020-09-28T06:47:18.910814Z",
     "shell.execute_reply": "2020-09-28T06:47:18.910176Z"
    },
    "papermill": {
     "duration": 0.108342,
     "end_time": "2020-09-28T06:47:18.910941",
     "exception": false,
     "start_time": "2020-09-28T06:47:18.802599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"php\\\\r public function loadtranslation  \\\\r {\\\\r     return $this->load  \\\\r         'translations' => function  relation $query  {\\\\r             if  $this->usefallback    {\\\\r                 $locale = $this->locale  ;\\\\r                 $countryfallbacklocale = $this->getfallbacklocale $locale ; // e.g. de-de => de\\\\r                 $locales = array_unique  $locale, $countryfallbacklocale, $this->getfallbacklocale    ;\\\\r \\\\r                 return $query->wherein $this->gettranslationstable  .'.'.$this->getlocalekey  , $locales ;\\\\r             }\\\\r \\\\r             return $query->where $this->gettranslationstable  .'.'.$this->getlocalekey  , $this->locale   ;\\\\r         },\\\\r       ;\\\\r }\\\\r    \\\\r \\\\r or maybe you could do this\\\\r \\\\r    php\\\\r public function loadtranslation  \\\\r {\\\\r     $query = $this->newquerywithoutrelationships  ->withtranslation  ;\\\\r     $query->eagerloadrelations  $this  ;\\\\r \\\\r     return $this;\\\\r }\\\\r\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Sample Body\n",
    "final_df.iloc[7][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:19.111768Z",
     "iopub.status.busy": "2020-09-28T06:47:19.110725Z",
     "iopub.status.idle": "2020-09-28T06:47:19.125317Z",
     "shell.execute_reply": "2020-09-28T06:47:19.124727Z"
    },
    "papermill": {
     "duration": 0.117436,
     "end_time": "2020-09-28T06:47:19.125432",
     "exception": false,
     "start_time": "2020-09-28T06:47:19.007996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450000 entries, 0 to 449999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   450000 non-null  object\n",
      " 1   body    450000 non-null  object\n",
      " 2   label   450000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing snippets/titles/descriptions\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    450000\n",
       "body     450000\n",
       "label    450000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "final_df.drop_duplicates(keep='first').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observer here, there are no duplicates in the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Bug','Feature','Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:19.566064Z",
     "iopub.status.busy": "2020-09-28T06:47:19.565291Z",
     "iopub.status.idle": "2020-09-28T06:47:19.567847Z",
     "shell.execute_reply": "2020-09-28T06:47:19.568537Z"
    },
    "papermill": {
     "duration": 0.12602,
     "end_time": "2020-09-28T06:47:19.568702",
     "exception": false,
     "start_time": "2020-09-28T06:47:19.442682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting each of title and body into lower case.\n",
    "final_df['title'] = final_df['title'].apply(lambda title: str(title).lower())\n",
    "final_df['body'] = final_df['body'].apply(lambda body: str(body).lower())\n",
    "test_df['title'] = test_df['title'].apply(lambda title: str(title).lower())\n",
    "test_df['body'] = test_df['body'].apply(lambda body: str(body).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:19.834311Z",
     "iopub.status.busy": "2020-09-28T06:47:19.829019Z",
     "iopub.status.idle": "2020-09-28T06:47:19.925017Z",
     "shell.execute_reply": "2020-09-28T06:47:19.924396Z"
    },
    "papermill": {
     "duration": 0.256478,
     "end_time": "2020-09-28T06:47:19.925143",
     "exception": false,
     "start_time": "2020-09-28T06:47:19.668665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculating the length of title and body\n",
    "final_df['title_len'] = final_df['title'].apply(lambda x: len(str(x).split()))\n",
    "final_df['body_len'] = final_df['body'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:20.127911Z",
     "iopub.status.busy": "2020-09-28T06:47:20.12724Z",
     "iopub.status.idle": "2020-09-28T06:47:20.155105Z",
     "shell.execute_reply": "2020-09-28T06:47:20.154439Z"
    },
    "papermill": {
     "duration": 0.132127,
     "end_time": "2020-09-28T06:47:20.155219",
     "exception": false,
     "start_time": "2020-09-28T06:47:20.023092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title_len</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450000.000000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>450000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.648267</td>\n",
       "      <td>6.951033</td>\n",
       "      <td>73.072449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.644653</td>\n",
       "      <td>3.269366</td>\n",
       "      <td>85.840179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>982.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label      title_len       body_len\n",
       "count  450000.000000  450000.000000  450000.000000\n",
       "mean        0.648267       6.951033      73.072449\n",
       "std         0.644653       3.269366      85.840179\n",
       "min         0.000000       2.000000       2.000000\n",
       "25%         0.000000       5.000000      21.000000\n",
       "50%         1.000000       6.000000      44.000000\n",
       "75%         1.000000       9.000000      90.000000\n",
       "max         2.000000      50.000000     982.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.09818,
     "end_time": "2020-09-28T06:47:20.351985",
     "exception": false,
     "start_time": "2020-09-28T06:47:20.253805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see, all articles have a title and body. Going with the intuition that the title is often more descriptive of the category, as well as to provide more text data to the model, we will add title to the body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:20.600889Z",
     "iopub.status.busy": "2020-09-28T06:47:20.599958Z",
     "iopub.status.idle": "2020-09-28T06:47:20.765014Z",
     "shell.execute_reply": "2020-09-28T06:47:20.764354Z"
    },
    "papermill": {
     "duration": 0.301003,
     "end_time": "2020-09-28T06:47:20.765152",
     "exception": false,
     "start_time": "2020-09-28T06:47:20.464149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fx(x):\n",
    "    return x['title'] + \" \" + x['body']   \n",
    "final_df['text']=final_df.apply(lambda x : fx(x),axis=1)\n",
    "test_df['text']=test_df.apply(lambda x : fx(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:20.99127Z",
     "iopub.status.busy": "2020-09-28T06:47:20.990444Z",
     "iopub.status.idle": "2020-09-28T06:47:20.995498Z",
     "shell.execute_reply": "2020-09-28T06:47:20.994783Z"
    },
    "papermill": {
     "duration": 0.130994,
     "end_time": "2020-09-28T06:47:20.99567",
     "exception": false,
     "start_time": "2020-09-28T06:47:20.864676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>title_len</th>\n",
       "      <th>body_len</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y-zoom piano roll</td>\n",
       "      <td>a y-zoom on the piano roll would be useful.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>y-zoom piano roll a y-zoom on the piano roll w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buggy behavior in selection</td>\n",
       "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>buggy behavior in selection ! screenshot from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto update feature</td>\n",
       "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>auto update feature hi,\\r \\r great job so far,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filter out noisy endpoints in logs</td>\n",
       "      <td>i think we should stop logging requests to:\\r ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>filter out noisy endpoints in logs i think we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>281</td>\n",
       "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                  y-zoom piano roll   \n",
       "1                        buggy behavior in selection   \n",
       "2                                auto update feature   \n",
       "3                 filter out noisy endpoints in logs   \n",
       "4  enable pid on / pid off alarm actions for ardu...   \n",
       "\n",
       "                                                body  label  title_len  \\\n",
       "0        a y-zoom on the piano roll would be useful.      1          3   \n",
       "1  ! screenshot from 2016-02-23 21 27 40  https:/...      0          4   \n",
       "2  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1          3   \n",
       "3  i think we should stop logging requests to:\\r ...      1          6   \n",
       "4  expected behavior\\r alarm actions pid on and p...      0         10   \n",
       "\n",
       "   body_len                                               text  \n",
       "0         9  y-zoom piano roll a y-zoom on the piano roll w...  \n",
       "1         9  buggy behavior in selection ! screenshot from ...  \n",
       "2        32  auto update feature hi,\\r \\r great job so far,...  \n",
       "3        17  filter out noisy endpoints in logs i think we ...  \n",
       "4       281  enable pid on / pid off alarm actions for ardu...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10125,
     "end_time": "2020-09-28T06:47:21.199828",
     "exception": false,
     "start_time": "2020-09-28T06:47:21.098578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is preprocessed, in NLP it is also known as text normalization. Some of the most common methods of text normalization are:\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100283,
     "end_time": "2020-09-28T06:47:21.40014",
     "exception": false,
     "start_time": "2020-09-28T06:47:21.299857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Tokenization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:21.604929Z",
     "iopub.status.busy": "2020-09-28T06:47:21.60406Z",
     "iopub.status.idle": "2020-09-28T06:47:21.606861Z",
     "shell.execute_reply": "2020-09-28T06:47:21.607382Z"
    },
    "papermill": {
     "duration": 0.107846,
     "end_time": "2020-09-28T06:47:21.607522",
     "exception": false,
     "start_time": "2020-09-28T06:47:21.499676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    lst=text.split()\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.09946,
     "end_time": "2020-09-28T06:47:21.808793",
     "exception": false,
     "start_time": "2020-09-28T06:47:21.709333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Replace new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:22.016634Z",
     "iopub.status.busy": "2020-09-28T06:47:22.015524Z",
     "iopub.status.idle": "2020-09-28T06:47:22.018689Z",
     "shell.execute_reply": "2020-09-28T06:47:22.019216Z"
    },
    "papermill": {
     "duration": 0.110901,
     "end_time": "2020-09-28T06:47:22.019378",
     "exception": false,
     "start_time": "2020-09-28T06:47:21.908477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_new_lines(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        i=i.replace(r'\\n', ' ').replace(r'\\r', ' ').replace(r'\\u', ' ')\n",
    "        new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100498,
     "end_time": "2020-09-28T06:47:22.22339",
     "exception": false,
     "start_time": "2020-09-28T06:47:22.122892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Removal of Punctuation Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:22.429682Z",
     "iopub.status.busy": "2020-09-28T06:47:22.42896Z",
     "iopub.status.idle": "2020-09-28T06:47:22.432477Z",
     "shell.execute_reply": "2020-09-28T06:47:22.431851Z"
    },
    "papermill": {
     "duration": 0.11005,
     "end_time": "2020-09-28T06:47:22.432586",
     "exception": false,
     "start_time": "2020-09-28T06:47:22.322536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        for  j in s.punctuation:\n",
    "            i=i.replace(j,' ')\n",
    "        new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10029,
     "end_time": "2020-09-28T06:47:22.633665",
     "exception": false,
     "start_time": "2020-09-28T06:47:22.533375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Removal of Numbers(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:22.845319Z",
     "iopub.status.busy": "2020-09-28T06:47:22.844159Z",
     "iopub.status.idle": "2020-09-28T06:47:22.847386Z",
     "shell.execute_reply": "2020-09-28T06:47:22.847884Z"
    },
    "papermill": {
     "duration": 0.11314,
     "end_time": "2020-09-28T06:47:22.848049",
     "exception": false,
     "start_time": "2020-09-28T06:47:22.734909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_numbers(lst):\n",
    "    nodig_lst=[]\n",
    "    new_lst=[]\n",
    "    for i in  lst:\n",
    "        for j in  s.digits:\n",
    "            i=i.replace(j,' ')\n",
    "        nodig_lst.append(i.strip())\n",
    "    for i in  nodig_lst:\n",
    "        if  i!='':\n",
    "            new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.099903,
     "end_time": "2020-09-28T06:47:23.049993",
     "exception": false,
     "start_time": "2020-09-28T06:47:22.95009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:23.260351Z",
     "iopub.status.busy": "2020-09-28T06:47:23.259652Z",
     "iopub.status.idle": "2020-09-28T06:47:23.262875Z",
     "shell.execute_reply": "2020-09-28T06:47:23.261946Z"
    },
    "papermill": {
     "duration": 0.112022,
     "end_time": "2020-09-28T06:47:23.262994",
     "exception": false,
     "start_time": "2020-09-28T06:47:23.150972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(lst):\n",
    "    stop=stopwords.words('english')\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        if i not in stop:\n",
    "            new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.099516,
     "end_time": "2020-09-28T06:47:23.464697",
     "exception": false,
     "start_time": "2020-09-28T06:47:23.365181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Lemmatization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:23.674974Z",
     "iopub.status.busy": "2020-09-28T06:47:23.673964Z",
     "iopub.status.idle": "2020-09-28T06:47:23.676989Z",
     "shell.execute_reply": "2020-09-28T06:47:23.677565Z"
    },
    "papermill": {
     "duration": 0.112587,
     "end_time": "2020-09-28T06:47:23.677733",
     "exception": false,
     "start_time": "2020-09-28T06:47:23.565146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "def lemmatization(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        i=lemmatizer.lemmatize(i)\n",
    "        new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.101256,
     "end_time": "2020-09-28T06:47:23.879421",
     "exception": false,
     "start_time": "2020-09-28T06:47:23.778165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Removing URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:24.086401Z",
     "iopub.status.busy": "2020-09-28T06:47:24.085343Z",
     "iopub.status.idle": "2020-09-28T06:47:24.088863Z",
     "shell.execute_reply": "2020-09-28T06:47:24.088179Z"
    },
    "papermill": {
     "duration": 0.110178,
     "end_time": "2020-09-28T06:47:24.088979",
     "exception": false,
     "start_time": "2020-09-28T06:47:23.978801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100172,
     "end_time": "2020-09-28T06:47:24.291098",
     "exception": false,
     "start_time": "2020-09-28T06:47:24.190926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:24.49933Z",
     "iopub.status.busy": "2020-09-28T06:47:24.498625Z",
     "iopub.status.idle": "2020-09-28T06:47:24.502414Z",
     "shell.execute_reply": "2020-09-28T06:47:24.50177Z"
    },
    "papermill": {
     "duration": 0.109392,
     "end_time": "2020-09-28T06:47:24.502535",
     "exception": false,
     "start_time": "2020-09-28T06:47:24.393143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_words(text):\n",
    "    return ' '.join(text).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.104358,
     "end_time": "2020-09-28T06:47:24.706999",
     "exception": false,
     "start_time": "2020-09-28T06:47:24.602641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Remove single letter characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:24.91723Z",
     "iopub.status.busy": "2020-09-28T06:47:24.916184Z",
     "iopub.status.idle": "2020-09-28T06:47:24.919879Z",
     "shell.execute_reply": "2020-09-28T06:47:24.919182Z"
    },
    "papermill": {
     "duration": 0.11279,
     "end_time": "2020-09-28T06:47:24.919998",
     "exception": false,
     "start_time": "2020-09-28T06:47:24.807208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_single_chars(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        if len(i)>1:\n",
    "            new_lst.append(i.strip())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:47:25.13141Z",
     "iopub.status.busy": "2020-09-28T06:47:25.130582Z",
     "iopub.status.idle": "2020-09-28T06:47:44.666623Z",
     "shell.execute_reply": "2020-09-28T06:47:44.666002Z"
    },
    "papermill": {
     "duration": 19.645775,
     "end_time": "2020-09-28T06:47:44.66674",
     "exception": false,
     "start_time": "2020-09-28T06:47:25.020965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaning Text\n",
    "def denoise_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = tokenization(text)\n",
    "    text = remove_new_lines(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = split_words(text)\n",
    "    text = remove_single_chars(text)\n",
    "    text = lemmatization(text)\n",
    "    return text\n",
    "\n",
    "final_df['text'] = final_df['text'].apply(lambda x: denoise_text(x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: denoise_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.252175,
     "end_time": "2020-09-28T06:50:02.082965",
     "exception": false,
     "start_time": "2020-09-28T06:50:01.83079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Creating Corpus of Words in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:02.613067Z",
     "iopub.status.busy": "2020-09-28T06:50:02.6022Z",
     "iopub.status.idle": "2020-09-28T06:50:02.723245Z",
     "shell.execute_reply": "2020-09-28T06:50:02.722662Z"
    },
    "papermill": {
     "duration": 0.390862,
     "end_time": "2020-09-28T06:50:02.723368",
     "exception": false,
     "start_time": "2020-09-28T06:50:02.332506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zoom', 'piano', 'roll', 'zoom', 'piano']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Corpus\n",
    "def get_corpus(text):\n",
    "    words = []\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            words.append(j.strip())\n",
    "    return words\n",
    "corpus = get_corpus(final_df.text)\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus += get_corpus(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:03.349491Z",
     "iopub.status.busy": "2020-09-28T06:50:03.343638Z",
     "iopub.status.idle": "2020-09-28T06:50:03.354287Z",
     "shell.execute_reply": "2020-09-28T06:50:03.353639Z"
    },
    "papermill": {
     "duration": 0.37351,
     "end_time": "2020-09-28T06:50:03.354457",
     "exception": false,
     "start_time": "2020-09-28T06:50:02.980947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 189039,\n",
       " 'error': 155620,\n",
       " 'version': 135163,\n",
       " 'java': 134569,\n",
       " 'user': 128590,\n",
       " 'add': 110787,\n",
       " 'issue': 102101,\n",
       " 'test': 97858,\n",
       " 'line': 94374,\n",
       " 'use': 91000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common words\n",
    "from collections import Counter\n",
    "counter = Counter(corpus)\n",
    "most_common = counter.most_common(10)\n",
    "most_common = dict(most_common)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:03.868503Z",
     "iopub.status.busy": "2020-09-28T06:50:03.867648Z",
     "iopub.status.idle": "2020-09-28T06:50:03.870945Z",
     "shell.execute_reply": "2020-09-28T06:50:03.870391Z"
    },
    "papermill": {
     "duration": 0.266045,
     "end_time": "2020-09-28T06:50:03.871066",
     "exception": false,
     "start_time": "2020-09-28T06:50:03.605021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def get_top_text_ngrams(corpus, n, g):\n",
    "    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.260613,
     "end_time": "2020-09-28T06:50:23.210117",
     "exception": false,
     "start_time": "2020-09-28T06:50:22.949504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:23.738244Z",
     "iopub.status.busy": "2020-09-28T06:50:23.73725Z",
     "iopub.status.idle": "2020-09-28T06:50:23.740793Z",
     "shell.execute_reply": "2020-09-28T06:50:23.740198Z"
    },
    "papermill": {
     "duration": 0.276224,
     "end_time": "2020-09-28T06:50:23.740902",
     "exception": false,
     "start_time": "2020-09-28T06:50:23.464678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#label encoding the categories. After this each category would be mapped to an integer.\n",
    "encoder = LabelEncoder()\n",
    "final_df['categoryEncoded'] = encoder.fit_transform(final_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:24.257481Z",
     "iopub.status.busy": "2020-09-28T06:50:24.256496Z",
     "iopub.status.idle": "2020-09-28T06:50:24.25989Z",
     "shell.execute_reply": "2020-09-28T06:50:24.259315Z"
    },
    "papermill": {
     "duration": 0.265192,
     "end_time": "2020-09-28T06:50:24.259999",
     "exception": false,
     "start_time": "2020-09-28T06:50:23.994807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_df['text'], final_df['categoryEncoded'], random_state = 43, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.260738,
     "end_time": "2020-09-28T06:50:51.502879",
     "exception": false,
     "start_time": "2020-09-28T06:50:51.242141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:58.642593Z",
     "iopub.status.busy": "2020-09-28T06:50:58.632166Z",
     "iopub.status.idle": "2020-09-28T06:50:58.740226Z",
     "shell.execute_reply": "2020-09-28T06:50:58.739057Z"
    },
    "papermill": {
     "duration": 0.41038,
     "end_time": "2020-09-28T06:50:58.740384",
     "exception": false,
     "start_time": "2020-09-28T06:50:58.330004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x=X_train.apply(lambda x: ''.join(i+' ' for i in x))\n",
    "test_x=X_test.apply(lambda x: ''.join(i+' '  for i in x))\n",
    "test_df_final = test_df['text'].apply(lambda x: ''.join(i+' '  for i in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.257249,
     "end_time": "2020-09-28T06:50:59.26032",
     "exception": false,
     "start_time": "2020-09-28T06:50:59.003071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Extraction\n",
    " \n",
    " Features are extracted from the dataset and TF-IDF(Term Frequency - Inverse Document Frequency) is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:50:59.863541Z",
     "iopub.status.busy": "2020-09-28T06:50:59.846746Z",
     "iopub.status.idle": "2020-09-28T06:51:00.999939Z",
     "shell.execute_reply": "2020-09-28T06:51:00.999304Z"
    },
    "papermill": {
     "duration": 1.482102,
     "end_time": "2020-09-28T06:51:01.000058",
     "exception": false,
     "start_time": "2020-09-28T06:50:59.517956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of features extracted: 10000\n",
      "['aa', 'aaa', 'aaaa', 'aab', 'aac', 'aad', 'aar', 'aarch', 'ab', 'aba', 'abandoned', 'abb', 'abbreviation', 'abc', 'abcd', 'abf', 'abi', 'ability', 'able', 'ably']\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.8 GiB for an array with shape (360000, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-d14849b08ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_arr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_arr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.8 GiB for an array with shape (360000, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(max_features=10000,min_df=6)\n",
    "train_1=tfidf.fit_transform(train_x)\n",
    "test_1=tfidf.transform(test_x)\n",
    "test_2=tfidf.transform(test_df_final)\n",
    "print(\"No. of features extracted:\", len(tfidf.get_feature_names()))\n",
    "print(tfidf.get_feature_names()[:20])\n",
    "\n",
    "train_arr=train_1.toarray()\n",
    "test_arr=test_1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr1=test_2.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.294841,
     "end_time": "2020-09-28T06:51:03.234334",
     "exception": false,
     "start_time": "2020-09-28T06:51:02.939493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Function for evaluation of model**\n",
    "\n",
    "This function finds the F1-score and Accuracy of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:51:03.827792Z",
     "iopub.status.busy": "2020-09-28T06:51:03.826944Z",
     "iopub.status.idle": "2020-09-28T06:51:03.829282Z",
     "shell.execute_reply": "2020-09-28T06:51:03.829848Z"
    },
    "papermill": {
     "duration": 0.297501,
     "end_time": "2020-09-28T06:51:03.830001",
     "exception": false,
     "start_time": "2020-09-28T06:51:03.5325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(y,y_pred):\n",
    "    print(\"Recall score of the model:\", round(recall_score(y_test, pred, average='weighted'), 3))\n",
    "    print(\"Precision score of the model:\", round(precision_score(y_test, pred, average='weighted'), 3))\n",
    "    print(\"F1 score of the model:\", round(f1_score(y,y_pred,average='micro'), 3))\n",
    "    print(\"Accuracy of the model:\", round(accuracy_score(y,y_pred),3))\n",
    "    print(\"Accuracy of the model in percentage:\", round(accuracy_score(y,y_pred)*100,3),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.268446,
     "end_time": "2020-09-28T06:51:04.361588",
     "exception": false,
     "start_time": "2020-09-28T06:51:04.093142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Function for Displaying the Confusion Matrix**\n",
    "\n",
    "This function displays the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:51:04.913799Z",
     "iopub.status.busy": "2020-09-28T06:51:04.913087Z",
     "iopub.status.idle": "2020-09-28T06:51:04.918656Z",
     "shell.execute_reply": "2020-09-28T06:51:04.918093Z"
    },
    "papermill": {
     "duration": 0.292274,
     "end_time": "2020-09-28T06:51:04.918845",
     "exception": false,
     "start_time": "2020-09-28T06:51:04.626571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_mat(color):\n",
    "    cm=confusion_matrix(y_test, pred)\n",
    "    plot_confusion_matrix(cm,\n",
    "                          categories,\n",
    "                          title='Confusion matrix')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.264027,
     "end_time": "2020-09-28T06:51:01.529867",
     "exception": false,
     "start_time": "2020-09-28T06:51:01.26584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.290527,
     "end_time": "2020-09-28T06:51:07.051748",
     "exception": false,
     "start_time": "2020-09-28T06:51:06.761221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:51:07.621992Z",
     "iopub.status.busy": "2020-09-28T06:51:07.620542Z",
     "iopub.status.idle": "2020-09-28T06:51:09.800991Z",
     "shell.execute_reply": "2020-09-28T06:51:09.801499Z"
    },
    "papermill": {
     "duration": 2.465327,
     "end_time": "2020-09-28T06:51:09.801675",
     "exception": false,
     "start_time": "2020-09-28T06:51:07.336348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm=LGBMClassifier()\n",
    "lgbm.fit(train_arr,y_train)\n",
    "pred=lgbm.predict(test_arr)\n",
    "\n",
    "print(\"first 20 actual labels\")\n",
    "print(y_test.tolist()[:20])\n",
    "print(\"first 20 predicted labels\")\n",
    "print(pred.tolist()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.274755,
     "end_time": "2020-09-28T06:51:10.352353",
     "exception": false,
     "start_time": "2020-09-28T06:51:10.077598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:51:10.980086Z",
     "iopub.status.busy": "2020-09-28T06:51:10.979042Z",
     "iopub.status.idle": "2020-09-28T06:51:11.017599Z",
     "shell.execute_reply": "2020-09-28T06:51:11.016732Z"
    },
    "papermill": {
     "duration": 0.389335,
     "end_time": "2020-09-28T06:51:11.017793",
     "exception": false,
     "start_time": "2020-09-28T06:51:10.628458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_model(y_test,pred)\n",
    "b=round(accuracy_score(y_test,pred)*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T06:51:11.640362Z",
     "iopub.status.busy": "2020-09-28T06:51:11.639679Z",
     "iopub.status.idle": "2020-09-28T06:51:12.392549Z",
     "shell.execute_reply": "2020-09-28T06:51:12.391969Z"
    },
    "papermill": {
     "duration": 1.041501,
     "end_time": "2020-09-28T06:51:12.392689",
     "exception": false,
     "start_time": "2020-09-28T06:51:11.351188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_mat('Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lgbm.predict(test_arr1)\n",
    "#create a submission dataframe\n",
    "submission_df = pd.DataFrame(pred, columns=['label'])\n",
    "#write a .csv file for submission\n",
    "submission_df.to_csv('lgbm_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
